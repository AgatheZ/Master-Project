{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import (KFold, StratifiedKFold, cross_val_predict,\n",
    "                                     cross_validate, train_test_split)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statistics\n",
    "import shap\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds loading and variables removal \n",
    "ds = pd.read_csv(r\"C:\\Users\\USER\\OneDrive\\Summer_project\\Azure\\annex study\\ds_annex_study.csv\", index_col = 'ID')\n",
    "ds = ds.drop(columns=['date','DOB', 'preexisting_cond', 'twoyears', 'fiveyears', 'death'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 years Counter({0: 61, 1: 24})\n",
      "5 years Counter({0: 46, 1: 39})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#Extra preprocessing (1-hot encoding)\n",
    "ds = ds.fillna(ds.mean())\n",
    "ds = ds.fillna(0)\n",
    "\n",
    "\n",
    "for variable in ['COPD', 'ILD', 'NTM']:\n",
    "    ds[variable][ds[variable] == 'Yes'] = 1\n",
    "    ds[variable][ds[variable] == 'No'] = 0\n",
    "\n",
    "ds['sex'][ds['sex'] == 'F'] = 0\n",
    "ds['sex'][ds['sex'] == 'M'] = 1\n",
    "\n",
    "ds.ethnicity = ds.ethnicity.astype('category').cat.codes\n",
    "\n",
    "labels2 = ds['dead2']\n",
    "labels5 = ds['dead5']\n",
    "\n",
    "ds = ds.drop(columns = ['dead2', 'dead5'])\n",
    "\n",
    "counter2 = Counter(labels2)\n",
    "counter5 = Counter(labels5)\n",
    "\n",
    "print('2 years', counter2)\n",
    "print('5 years', counter5)\n",
    "\n",
    "counter = counter5\n",
    "\n",
    "# estimate scale_pos_weight value\n",
    "estimate = counter[0] / counter[1]\n",
    "estimate2 = counter[1]/counter[0]\n",
    "\n",
    "#dataset split \n",
    "X_train, X_test, y_train, y_test = train_test_split(ds, labels2, test_size=0.2, shuffle = True, random_state=random_state)\n",
    "features = ds.columns\n",
    "ds = np.array(ds)\n",
    "labels2 = np.array(labels2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 64 0 3.0 38.0 15.0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 58 5 5.0 37.0 22.0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      " [1 54 1 4.0 43.0 21.2764705882353 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0\n",
      "  1 1]\n",
      " [0 25 1 4.0 42.0 19.1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 61 1 40.0 34.0 17.7 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 1]\n",
      " [1 62 1 13.0 39.0 19.5 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 1]\n",
      " [1 74 1 2.0 42.0 25.3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 84 1 9.0 35.0 22.9 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0]\n",
      " [0 37 1 159.0 38.0 13.5 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0]\n",
      " [0 51 1 10.0 43.0 21.6 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1]\n",
      " [0 66 1 19.0 30.0 20.8 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 62 1 2.0 45.0 22.3 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 68 1 117.0 36.0 26.0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0]\n",
      " [1 82 1 30.0 33.0 21.2764705882353 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      "  0 0]\n",
      " [0 53 5 20.0 32.0 21.2764705882353 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0]\n",
      " [0 64 10 36.37179487179487 38.1025641025641 21.2764705882353 1 0 1 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 61 10 4.0 38.1025641025641 21.2764705882353 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      "  0 0 0 0 0 0 1 1]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y must be a structured array with the first field being a binary class event indicator and the second field the time of the event/censoring",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\OneDrive\\Summer_project\\Azure\\Master-Project\\Additional_analysis\\model.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive/Summer_project/Azure/Master-Project/Additional_analysis/model.ipynb#ch0000003?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive/Summer_project/Azure/Master-Project/Additional_analysis/model.ipynb#ch0000003?line=24'>25</a>\u001b[0m xgbc \u001b[39m=\u001b[39m model\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive/Summer_project/Azure/Master-Project/Additional_analysis/model.ipynb#ch0000003?line=25'>26</a>\u001b[0m xgbc\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive/Summer_project/Azure/Master-Project/Additional_analysis/model.ipynb#ch0000003?line=26'>27</a>\u001b[0m y_pred \u001b[39m=\u001b[39m xgbc\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/OneDrive/Summer_project/Azure/Master-Project/Additional_analysis/model.ipynb#ch0000003?line=27'>28</a>\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sksurv\\ensemble\\forest.py:89\u001b[0m, in \u001b[0;36m_BaseSurvivalForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m\"\"\"Build a forest of survival trees from the training set (X, y).\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \n\u001b[0;32m     74\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mself\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     88\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(X, ensure_min_samples\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m---> 89\u001b[0m event, time \u001b[39m=\u001b[39m check_array_survival(X, y)\n\u001b[0;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m     92\u001b[0m time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sksurv\\util.py:190\u001b[0m, in \u001b[0;36mcheck_array_survival\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_array_survival\u001b[39m(X, y):\n\u001b[0;32m    167\u001b[0m     \u001b[39m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \n\u001b[0;32m    169\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[39m        Time of event or censoring.\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m     event, time \u001b[39m=\u001b[39m check_y_survival(y)\n\u001b[0;32m    191\u001b[0m     check_consistent_length(X, event, time)\n\u001b[0;32m    192\u001b[0m     \u001b[39mreturn\u001b[39;00m event, time\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sksurv\\util.py:133\u001b[0m, in \u001b[0;36mcheck_y_survival\u001b[1;34m(y_or_event, allow_all_censored, *args)\u001b[0m\n\u001b[0;32m    130\u001b[0m y \u001b[39m=\u001b[39m y_or_event\n\u001b[0;32m    132\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(y, numpy\u001b[39m.\u001b[39mndarray) \u001b[39mor\u001b[39;00m y\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mfields \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(y\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mfields) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m--> 133\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39my must be a structured array with the first field\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    134\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m being a binary class event indicator and the second field\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    135\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m the time of the event/censoring\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    137\u001b[0m event_field, time_field \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mnames\n\u001b[0;32m    138\u001b[0m y_event \u001b[39m=\u001b[39m y[event_field]\n",
      "\u001b[1;31mValueError\u001b[0m: y must be a structured array with the first field being a binary class event indicator and the second field the time of the event/censoring"
     ]
    }
   ],
   "source": [
    "SHAP = True\n",
    "\n",
    "# model = RandomForestClassifier(random_state=random_state, class_weight = {0:estimate2, 1:estimate})\n",
    "# model = XGBClassifier(random_state=random_state, scale_pos_weight = estimate)\n",
    "# model = XGBClassifier(random_state=random_state, scale_pos_weight = estimate)\n",
    "model = RandomSurvivalForest(n_estimators=1000,\n",
    "                           min_samples_split=10,\n",
    "                           min_samples_leaf=15,\n",
    "                           max_features=\"sqrt\",\n",
    "                           n_jobs=-1,\n",
    "                           random_state=random_state)\n",
    "# model = LogisticRegression(random_state = random_state)\n",
    "labels = labels5\n",
    "\n",
    "#model training\n",
    "skf = KFold(n_splits=5, random_state=random_state, shuffle=True)\n",
    "acc = []\n",
    "cms = []\n",
    "f1 = []\n",
    "\n",
    "for train_index, test_index in skf.split(ds, labels):\n",
    "    X_train, X_test = ds[train_index], ds[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    print(X_test)\n",
    "    xgbc = model\n",
    "    xgbc.fit(X_train, y_train)\n",
    "    y_pred = xgbc.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cf = confusion_matrix(y_test, y_pred)\n",
    "    fscore = f1_score(y_test, y_pred)\n",
    "    acc.append(accuracy)\n",
    "    cms.append(cf)\n",
    "    f1.append(fscore)\n",
    "    print('Accuracy:', round(accuracy,2))\n",
    "    print('F1-score:', round(fscore,2))\n",
    "    print('Confusion matrix:\\n', cf)\n",
    "\n",
    "    if SHAP:\n",
    "        ex = shap.Explainer(model)\n",
    "        shaps_values = ex.shap_values(X_test)\n",
    "        plt.figure(figsize = (15,15))\n",
    "        shap.summary_plot(shaps_values, pd.DataFrame(X_test.astype('float'), columns = features), show = True)\n",
    "        plt.savefig('SHAP_CPA.png',bbox_inches='tight', dpi=300)\n",
    "        SHAP = False\n",
    "\n",
    "print('Averaged accuracy (5-folds): %.3f ±  %.3f' % (np.mean(acc), statistics.stdev(acc)))\n",
    "print('Averaged f1-score (5-folds): %.3f ±  %.3f' % (np.mean(f1), statistics.stdev(f1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d5c1156327dacead463cc502c55ebae8ce9c8c01979cf154173ff808e75bf55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
